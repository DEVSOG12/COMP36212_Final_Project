\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Part I - Stochastic Gradient Descent}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Implementation of Batch SGD}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Gradient Verification}{1}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}SGD Training Results}{2}{subsection.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces SGD accuracy over iterations with batch size $m=10$ and learning rate $\eta =0.1$.}}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sgd_accuracy}{{1}{2}{SGD accuracy over iterations with batch size $m=10$ and learning rate $\eta =0.1$}{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces SGD loss over iterations with batch size $m=10$ and learning rate $\eta =0.1$.}}{2}{figure.caption.2}\protected@file@percent }
\newlabel{fig:sgd_loss}{{2}{2}{SGD loss over iterations with batch size $m=10$ and learning rate $\eta =0.1$}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}SGD Performance Analysis}{2}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Part II - Improving Convergence}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Effect of Batch Size and Learning Rate}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Batch Size Analysis}{3}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Effect of batch size on accuracy with learning rate $\eta =0.1$.}}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:batch_size_accuracy}{{3}{3}{Effect of batch size on accuracy with learning rate $\eta =0.1$}{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Effect of batch size on loss with learning rate $\eta =0.1$.}}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:batch_size_loss}{{4}{4}{Effect of batch size on loss with learning rate $\eta =0.1$}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Learning Rate Analysis}{4}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Effect of learning rate on accuracy with batch size $m=10$.}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:learning_rate_accuracy}{{5}{5}{Effect of learning rate on accuracy with batch size $m=10$}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Effect of learning rate on loss with batch size $m=10$.}}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:learning_rate_loss}{{6}{5}{Effect of learning rate on loss with batch size $m=10$}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Learning Rate Decay Implementation}{6}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Effect of learning rate decay on accuracy.}}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:lr_decay_accuracy}{{7}{6}{Effect of learning rate decay on accuracy}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Effect of learning rate decay on loss.}}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:lr_decay_loss}{{8}{7}{Effect of learning rate decay on loss}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Momentum Implementation}{7}{subsection.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Effect of momentum on accuracy.}}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:momentum_accuracy}{{9}{8}{Effect of momentum on accuracy}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Effect of momentum on loss.}}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:momentum_loss}{{10}{8}{Effect of momentum on loss}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Combined Learning Rate Decay and Momentum}{8}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Effect of combined approaches on accuracy.}}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:combined_accuracy}{{11}{9}{Effect of combined approaches on accuracy}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Effect of combined approaches on loss.}}{9}{figure.caption.12}\protected@file@percent }
\newlabel{fig:combined_loss}{{12}{9}{Effect of combined approaches on loss}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Part III - Adaptive Learning}{10}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Adam Optimizer}{10}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Adam Performance Analysis}{10}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Adam vs other optimization methods - accuracy.}}{11}{figure.caption.13}\protected@file@percent }
\newlabel{fig:adam_accuracy}{{13}{11}{Adam vs other optimization methods - accuracy}{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Adam vs other optimization methods - loss.}}{11}{figure.caption.14}\protected@file@percent }
\newlabel{fig:adam_loss}{{14}{11}{Adam vs other optimization methods - loss}{figure.caption.14}{}}
\bibcite{kingma2014adam}{1}
\bibcite{lecun1998gradient}{2}
\bibcite{bottou2008tradeoffs}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Optimal Hyperparameters and Comparison}{12}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{12}{section.4}\protected@file@percent }
\gdef \@abspage@last{12}
