\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{none/global//global/global}
\abx@aux@cite{0}{rumelhart1986learning}
\abx@aux@segm{0}{0}{rumelhart1986learning}
\abx@aux@cite{0}{bottou2012sgdtricks}
\abx@aux@segm{0}{0}{bottou2012sgdtricks}
\abx@aux@cite{0}{robbins1951stochastic}
\abx@aux@segm{0}{0}{robbins1951stochastic}
\abx@aux@cite{0}{glorot2010understanding}
\abx@aux@segm{0}{0}{glorot2010understanding}
\abx@aux@cite{0}{goodfellow2016deep}
\abx@aux@segm{0}{0}{goodfellow2016deep}
\@writefile{toc}{\contentsline {section}{\numberline {1}Part I - Stochastic Gradient Descent}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Implementation of Batch SGD}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Gradient Verification}{1}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}SGD Training Results}{2}{subsection.1.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sgd_accuracy}{{1a}{2}{SGD accuracy over iterations with batch size $m=10$ and learning rate $\eta =0.1$}{figure.caption.1}{}}
\newlabel{sub@fig:sgd_accuracy}{{a}{2}{SGD accuracy over iterations with batch size $m=10$ and learning rate $\eta =0.1$}{figure.caption.1}{}}
\newlabel{fig:sgd_loss}{{1b}{2}{SGD loss over iterations with batch size $m=10$ and learning rate $\eta =0.1$}{figure.caption.1}{}}
\newlabel{sub@fig:sgd_loss}{{b}{2}{SGD loss over iterations with batch size $m=10$ and learning rate $\eta =0.1$}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}SGD Performance Analysis}{2}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Part II - Improving Convergence}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Effect of Batch Size and Learning Rate}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Batch Size Analysis}{2}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{fig:batch_size_accuracy}{{2a}{2}{Effect of batch size on accuracy with learning rate $\eta =0.1$}{figure.caption.2}{}}
\newlabel{sub@fig:batch_size_accuracy}{{a}{2}{Effect of batch size on accuracy with learning rate $\eta =0.1$}{figure.caption.2}{}}
\newlabel{fig:batch_size_loss}{{2b}{2}{Effect of batch size on loss with learning rate $\eta =0.1$}{figure.caption.2}{}}
\newlabel{sub@fig:batch_size_loss}{{b}{2}{Effect of batch size on loss with learning rate $\eta =0.1$}{figure.caption.2}{}}
\abx@aux@cite{0}{keskar2017large}
\abx@aux@segm{0}{0}{keskar2017large}
\abx@aux@cite{0}{bottou2008tradeoffs}
\abx@aux@segm{0}{0}{bottou2008tradeoffs}
\abx@aux@cite{0}{goodfellow2016deep}
\abx@aux@segm{0}{0}{goodfellow2016deep}
\abx@aux@cite{0}{mandt2017stochastic}
\abx@aux@segm{0}{0}{mandt2017stochastic}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Learning Rate Analysis}{3}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{fig:learning_rate_accuracy}{{3a}{3}{Effect of learning rate on accuracy with batch size $m=10$}{figure.caption.3}{}}
\newlabel{sub@fig:learning_rate_accuracy}{{a}{3}{Effect of learning rate on accuracy with batch size $m=10$}{figure.caption.3}{}}
\newlabel{fig:learning_rate_loss}{{3b}{3}{Effect of learning rate on loss with batch size $m=10$}{figure.caption.3}{}}
\newlabel{sub@fig:learning_rate_loss}{{b}{3}{Effect of learning rate on loss with batch size $m=10$}{figure.caption.3}{}}
\abx@aux@cite{0}{smith2017cyclical}
\abx@aux@segm{0}{0}{smith2017cyclical}
\abx@aux@cite{0}{qian1999momentum}
\abx@aux@segm{0}{0}{qian1999momentum}
\abx@aux@cite{0}{sutskever2013importance}
\abx@aux@segm{0}{0}{sutskever2013importance}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Learning Rate Decay Implementation}{4}{subsection.2.2}\protected@file@percent }
\newlabel{fig:lr_decay_accuracy}{{4a}{4}{Effect of learning rate decay on accuracy}{figure.caption.4}{}}
\newlabel{sub@fig:lr_decay_accuracy}{{a}{4}{Effect of learning rate decay on accuracy}{figure.caption.4}{}}
\newlabel{fig:lr_decay_loss}{{4b}{4}{Effect of learning rate decay on loss}{figure.caption.4}{}}
\newlabel{sub@fig:lr_decay_loss}{{b}{4}{Effect of learning rate decay on loss}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Momentum Implementation}{4}{subsection.2.3}\protected@file@percent }
\newlabel{fig:momentum_accuracy}{{5a}{5}{Effect of momentum on accuracy}{figure.caption.5}{}}
\newlabel{sub@fig:momentum_accuracy}{{a}{5}{Effect of momentum on accuracy}{figure.caption.5}{}}
\newlabel{fig:momentum_loss}{{5b}{5}{Effect of momentum on loss}{figure.caption.5}{}}
\newlabel{sub@fig:momentum_loss}{{b}{5}{Effect of momentum on loss}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Combined Learning Rate Decay and Momentum}{5}{subsection.2.4}\protected@file@percent }
\newlabel{fig:combined_accuracy}{{6a}{5}{Effect of combined approaches on accuracy}{figure.caption.6}{}}
\newlabel{sub@fig:combined_accuracy}{{a}{5}{Effect of combined approaches on accuracy}{figure.caption.6}{}}
\newlabel{fig:combined_loss}{{6b}{5}{Effect of combined approaches on loss}{figure.caption.6}{}}
\newlabel{sub@fig:combined_loss}{{b}{5}{Effect of combined approaches on loss}{figure.caption.6}{}}
\abx@aux@cite{0}{kingma2014adam}
\abx@aux@segm{0}{0}{kingma2014adam}
\@writefile{toc}{\contentsline {section}{\numberline {3}Part III - Adaptive Learning}{6}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Adam Optimizer}{6}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Adam Performance Analysis}{6}{subsection.3.2}\protected@file@percent }
\newlabel{fig:adam_accuracy}{{7a}{6}{Adam vs other optimization methods - accuracy}{figure.caption.7}{}}
\newlabel{sub@fig:adam_accuracy}{{a}{6}{Adam vs other optimization methods - accuracy}{figure.caption.7}{}}
\newlabel{fig:adam_loss}{{7b}{6}{Adam vs other optimization methods - loss}{figure.caption.7}{}}
\newlabel{sub@fig:adam_loss}{{b}{6}{Adam vs other optimization methods - loss}{figure.caption.7}{}}
\abx@aux@cite{0}{loshchilov2019adamw}
\abx@aux@segm{0}{0}{loshchilov2019adamw}
\abx@aux@cite{0}{wilson2017marginal}
\abx@aux@segm{0}{0}{wilson2017marginal}
\abx@aux@cite{0}{reddi2018convergence}
\abx@aux@segm{0}{0}{reddi2018convergence}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Optimal Hyperparameters and Comparison}{7}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments Details}{7}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{8}{section.5}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{4467E44B7B3395AA786E968C9E1BF69B}
\abx@aux@defaultrefcontext{0}{rumelhart1986learning}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{bottou2012sgdtricks}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{robbins1951stochastic}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{glorot2010understanding}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{goodfellow2016deep}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{keskar2017large}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{bottou2008tradeoffs}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{mandt2017stochastic}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{smith2017cyclical}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{qian1999momentum}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{sutskever2013importance}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{kingma2014adam}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{loshchilov2019adamw}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{wilson2017marginal}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{reddi2018convergence}{none/global//global/global}
\gdef \@abspage@last{9}
